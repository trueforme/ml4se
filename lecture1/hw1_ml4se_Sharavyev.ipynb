{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNa8g5xWK65MMLe3zFB6wS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trueforme/ml4se/blob/main/lecture1/hw1_ml4se_Sharavyev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель - GPT5 Thinking, с подпиской PLUS; Не уверен, что было честно использовать эту модель, так как считаю ее довольно мощной, но в правилах ограничения на модель не было."
      ],
      "metadata": {
        "id": "3dQywMu_1XhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT: Задание:\n",
        "Сгенерируй простую программу на python, реализующую dfs, в файле не должно быть if __name__. Сгенерированный код должен содержать tabs ( \\t ) в виде отступов для строк кода, вместо пробелов. Должен содержать лишние \\n ( назовем это \"шумом\"). Затем этот файл нужно перевести в .txt формат, где будут видны все whitespaces символы. Затем следующее подзадание:\n",
        "Нужно обработать этот  текстовый файл. ИЗМЕНИ ТОЛЬКО ТАК, как я попрошу, и НИКАК ИНАЧЕ:\n",
        "1. Нужно убрать ВСЕ комментарии\n",
        "2. ТАБЫ ( tabs ) заменить соответствующим им ПРОБЕЛАМ для таких же отступов\n",
        "3. ВСЕ НЕЗНАЧАЩИЕ пробельные символы ( whitespaces) убрать\n",
        "4. ВСЕ названия ПЕРЕМЕННЫХ, ФУНКЦИЙ, КЛАССОВ заменить на name_{old_name} В конце проверь, что ты сделал как требуется, и не добавил ничего лишнего\n",
        "\n",
        "В итоге должно получиться 4 файла:\n",
        "1) raw.py, с \\t, лишними \\n, как я описал\n",
        "2) raw.txt, переведенный raw.py в txt формат\n",
        "3) clean.txt, очищенный по правилам подзадания raw.txt\n",
        "4) clean.py, переведенный clean.txt в питоновский файл, сохраняющий полную работоспособность в точности как в raw.py\n"
      ],
      "metadata": {
        "id": "WjLWcVDO1WaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Доп Промпт: Все отлично! Единственное замечание, которое нужно исправить: в raw.py, raw.txt в конце строк должны быть лишние ( незначающие) \\n. То есть как минимум в кнце каждой строчки вместо \\n в конце должно быть \\n\\n. Остальное задание остается прежним. Переделай."
      ],
      "metadata": {
        "id": "CfJi0GTm6eP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple DFS implementation (with tabs and noise)\n",
        "\n",
        "def dfs(graph, start, visited=None):\n",
        "\n",
        "\tif visited is None:\n",
        "\n",
        "\t\tvisited = set()\n",
        "\n",
        "\t# mark visited\n",
        "\n",
        "\tvisited.add(start)\n",
        "\n",
        "\tfor neighbor in graph.get(start, []):\n",
        "\n",
        "\t\tif neighbor not in visited:\n",
        "\n",
        "\t\t\tdfs(graph, neighbor, visited)\n",
        "\n",
        "\treturn visited\n",
        "\n",
        "# sample graph\n",
        "\n",
        "graph = {\n",
        "\n",
        "\t'A': ['B', 'C'],\n",
        "\n",
        "\t'B': ['D'],\n",
        "\n",
        "\t'C': ['E'],\n",
        "\n",
        "\t'D': [],\n",
        "\n",
        "\t'E': []\n",
        "\n",
        "}\n",
        "\n",
        "start = 'A'\n",
        "\n",
        "result = dfs(graph, start)\n",
        "\n",
        "print(sorted(result))\n",
        "\n"
      ],
      "metadata": {
        "id": "KwWVOEtv6TS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def name_dfs(name_graph, name_start, name_visited=None):\n",
        "    if name_visited is None:\n",
        "        name_visited = set()\n",
        "    name_visited.add(name_start)\n",
        "    for name_neighbor in name_graph.get(name_start, []):\n",
        "        if name_neighbor not in name_visited:\n",
        "            name_dfs(name_graph, name_neighbor, name_visited)\n",
        "    return name_visited\n",
        "name_graph = {'A': ['B', 'C'], 'B': ['D'], 'C': ['E'], 'D': [], 'E': []}\n",
        "name_start = 'A'\n",
        "name_result = name_dfs(name_graph, name_start)\n",
        "print(sorted(name_result))\n"
      ],
      "metadata": {
        "id": "CdHgJXpC6p6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код нейронки:"
      ],
      "metadata": {
        "id": "OVpm7zTs6vGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild the files with the requested change: each line in raw.py should have *two* newlines (\"\\n\\n\")\n",
        "# and raw.txt should display these as visible \\\\n\\\\n at the end of each line.\n",
        "# The rest of the processing (cleaning steps, renaming, etc.) stays the same.\n",
        "\n",
        "import os, io, re, ast, contextlib, runpy\n",
        "\n",
        "BASE = \"/mnt/data\"\n",
        "\n",
        "# 1) Create raw.py with tabs and double newlines after each line\n",
        "raw_py_path = os.path.join(BASE, \"raw.py\")\n",
        "raw_code_lines = [\n",
        "    \"# Simple DFS implementation (with tabs and noise)\",\n",
        "    \"def dfs(graph, start, visited=None):\",\n",
        "    \"\\tif visited is None:\",\n",
        "    \"\\t\\tvisited = set()\",\n",
        "    \"\\t# mark visited\",\n",
        "    \"\\tvisited.add(start)\",\n",
        "    \"\\tfor neighbor in graph.get(start, []):\",\n",
        "    \"\\t\\tif neighbor not in visited:\",\n",
        "    \"\\t\\t\\tdfs(graph, neighbor, visited)\",\n",
        "    \"\\treturn visited\",\n",
        "    \"# sample graph\",\n",
        "    \"graph = {\",\n",
        "    \"\\t'A': ['B', 'C'],\",\n",
        "    \"\\t'B': ['D'],\",\n",
        "    \"\\t'C': ['E'],\",\n",
        "    \"\\t'D': [],\",\n",
        "    \"\\t'E': []\",\n",
        "    \"}\",\n",
        "    \"start = 'A'\",\n",
        "    \"result = dfs(graph, start)\",\n",
        "    \"print(sorted(result))\"\n",
        "]\n",
        "\n",
        "raw_code = \"\\n\\n\".join(raw_code_lines) + \"\\n\\n\"  # add double newlines between lines\n",
        "\n",
        "with open(raw_py_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "    f.write(raw_code)\n",
        "\n",
        "# 2) Produce raw.txt where \\t and \\n are visible, with double \\n shown as \\\\n\\\\n\n",
        "def to_visible_whitespace_double(txt: str) -> str:\n",
        "    lines = txt.splitlines(keepends=True)\n",
        "    out_lines = []\n",
        "    for line in lines:\n",
        "        # Replace tabs with literal \\t\n",
        "        vis = line.replace(\"\\t\", \"\\\\t\")\n",
        "        # Replace single or double newlines with visible \\n\\n\n",
        "        count_newlines = len(line) - len(line.rstrip(\"\\n\"))\n",
        "        vis = vis.rstrip(\"\\n\") + (\"\\\\n\" * count_newlines)\n",
        "        out_lines.append(vis)\n",
        "    return \"\\n\".join(out_lines)\n",
        "\n",
        "raw_txt_path = os.path.join(BASE, \"raw.txt\")\n",
        "raw_visible = to_visible_whitespace_double(raw_code)\n",
        "with open(raw_txt_path, \"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
        "    f.write(raw_visible)\n",
        "\n",
        "# 3) Transform raw.txt -> clean.txt / clean.py as before\n",
        "def from_visible_whitespace(txt: str) -> str:\n",
        "    lines = txt.splitlines()\n",
        "    real_lines = []\n",
        "    for line in lines:\n",
        "        content = line.replace(\"\\\\t\", \"\\t\")\n",
        "        # Replace visible \\n\\n or single \\n\n",
        "        content = re.sub(r\"(\\\\n){2}\", \"\\n\\n\", content)\n",
        "        content = re.sub(r\"(?<!\\\\)\\\\n\", \"\\n\", content)\n",
        "        real_lines.append(content)\n",
        "    return \"\\n\".join(real_lines) + \"\\n\"\n",
        "\n",
        "with open(raw_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_txt_content = f.read()\n",
        "\n",
        "code_from_txt = from_visible_whitespace(raw_txt_content)\n",
        "\n",
        "def strip_comments(src: str) -> str:\n",
        "    out_lines = []\n",
        "    for line in src.splitlines():\n",
        "        in_single = in_double = escape = False\n",
        "        cut_index = None\n",
        "        for i, ch in enumerate(line):\n",
        "            if escape:\n",
        "                escape = False\n",
        "                continue\n",
        "            if ch == \"\\\\\":\n",
        "                escape = True\n",
        "                continue\n",
        "            if ch == \"'\" and not in_double:\n",
        "                in_single = not in_single\n",
        "            elif ch == '\"' and not in_single:\n",
        "                in_double = not in_double\n",
        "            elif ch == \"#\" and not in_single and not in_double:\n",
        "                cut_index = i\n",
        "                break\n",
        "        if cut_index is not None:\n",
        "            out_lines.append(line[:cut_index])\n",
        "        else:\n",
        "            out_lines.append(line)\n",
        "    return \"\\n\".join(out_lines) + \"\\n\"\n",
        "\n",
        "no_comments = strip_comments(code_from_txt)\n",
        "\n",
        "def tabs_to_spaces(src: str, tabsize: int = 4) -> str:\n",
        "    out_lines = []\n",
        "    for line in src.splitlines():\n",
        "        leading_tabs = len(line) - len(line.lstrip(\"\\t\"))\n",
        "        prefix = \" \" * (leading_tabs * tabsize)\n",
        "        rest = line.lstrip(\"\\t\").replace(\"\\t\", \" \" * tabsize)\n",
        "        out_lines.append(prefix + rest)\n",
        "    return \"\\n\".join(out_lines) + \"\\n\"\n",
        "\n",
        "spaces_code = tabs_to_spaces(no_comments, tabsize=4)\n",
        "\n",
        "def remove_non_significant_ws(src: str) -> str:\n",
        "    lines = [ln.rstrip(\" \") for ln in src.splitlines()]\n",
        "    lines = [ln for ln in lines if ln.strip() != \"\"]\n",
        "    return \"\\n\".join(lines) + \"\\n\"\n",
        "\n",
        "minified_ws = remove_non_significant_ws(spaces_code)\n",
        "\n",
        "SAFE_EXCLUSIONS = {\"print\", \"set\", \"sorted\"}\n",
        "\n",
        "class Renamer(ast.NodeTransformer):\n",
        "    def __init__(self, mapping):\n",
        "        self.mapping = mapping\n",
        "    def visit_FunctionDef(self, node):\n",
        "        if node.name in self.mapping:\n",
        "            node.name = self.mapping[node.name]\n",
        "        self.generic_visit(node)\n",
        "        return node\n",
        "    def visit_ClassDef(self, node):\n",
        "        if node.name in self.mapping:\n",
        "            node.name = self.mapping[node.name]\n",
        "        self.generic_visit(node)\n",
        "        return node\n",
        "    def visit_Name(self, node):\n",
        "        if node.id in self.mapping:\n",
        "            node.id = self.mapping[node.id]\n",
        "        return node\n",
        "    def visit_arg(self, node):\n",
        "        if node.arg in self.mapping:\n",
        "            node.arg = self.mapping[node.arg]\n",
        "        return node\n",
        "\n",
        "tree = ast.parse(minified_ws)\n",
        "names_to_rename = set()\n",
        "\n",
        "class Collector(ast.NodeVisitor):\n",
        "    def visit_FunctionDef(self, node):\n",
        "        names_to_rename.add(node.name)\n",
        "        for a in node.args.args:\n",
        "            names_to_rename.add(a.arg)\n",
        "        self.generic_visit(node)\n",
        "    def visit_ClassDef(self, node):\n",
        "        names_to_rename.add(node.name)\n",
        "        self.generic_visit(node)\n",
        "    def visit_Assign(self, node):\n",
        "        for t in node.targets:\n",
        "            if isinstance(t, ast.Name):\n",
        "                names_to_rename.add(t.id)\n",
        "        self.generic_visit(node)\n",
        "    def visit_For(self, node):\n",
        "        if isinstance(node.target, ast.Name):\n",
        "            names_to_rename.add(node.target.id)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "Collector().visit(tree)\n",
        "def is_valid_identifier(name: str) -> bool:\n",
        "    return re.match(r\"^[A-Za-z_][A-Za-z_0-9]*$\", name) is not None\n",
        "\n",
        "final_names = {n for n in names_to_rename if is_valid_identifier(n) and n not in SAFE_EXCLUSIONS}\n",
        "mapping = {n: f\"name_{n}\" for n in sorted(final_names)}\n",
        "\n",
        "renamer = Renamer(mapping)\n",
        "new_tree = renamer.visit(tree)\n",
        "ast.fix_missing_locations(new_tree)\n",
        "clean_code = ast.unparse(new_tree) + \"\\n\"\n",
        "\n",
        "clean_txt_path = os.path.join(BASE, \"clean.txt\")\n",
        "def to_visible_for_clean(txt: str) -> str:\n",
        "    lines = txt.splitlines(keepends=True)\n",
        "    out_lines = []\n",
        "    for line in lines:\n",
        "        vis = line\n",
        "        if vis.endswith(\"\\n\"):\n",
        "            vis = vis[:-1] + \"\\\\n\"\n",
        "        out_lines.append(vis)\n",
        "    return \"\\n\".join(out_lines)\n",
        "\n",
        "clean_visible = to_visible_for_clean(clean_code)\n",
        "with open(clean_txt_path, \"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
        "    f.write(clean_visible)\n",
        "\n",
        "clean_py_path = os.path.join(BASE, \"clean.py\")\n",
        "def visible_to_python(txt: str) -> str:\n",
        "    lines = txt.splitlines()\n",
        "    real_lines = []\n",
        "    for line in lines:\n",
        "        if line.endswith(\"\\\\n\"):\n",
        "            content = line[:-2]\n",
        "        else:\n",
        "            content = line\n",
        "        real_lines.append(content)\n",
        "    return \"\\n\".join(real_lines) + \"\\n\"\n",
        "\n",
        "with open(clean_py_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "    f.write(visible_to_python(clean_visible))\n",
        "\n",
        "buf = io.StringIO()\n",
        "with contextlib.redirect_stdout(buf):\n",
        "    runpy.run_path(clean_py_path, run_name=\"__main__\")\n",
        "output = buf.getvalue()\n",
        "\n",
        "raw_py_path, raw_txt_path, clean_txt_path, clean_py_path, output\n"
      ],
      "metadata": {
        "id": "h4gz67A36xn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}